{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-aiconfig\n",
    "\n",
    "import openai\n",
    "\n",
    "# Use your OpenAI Key\n",
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the original completion function\n",
    "original_create = openai.chat.completions.create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "def pretty_print_file(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        pp = pprint.PrettyPrinter(indent=4, width = 150)\n",
    "        pp.pprint(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Completion Response: \n",
      "ChatCompletion(id='chatcmpl-8Q7IE1LMsEJeBOaHJVdJdn719HVgM', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None))], created=1701235254, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=8, total_tokens=17))\n",
      "\n",
      "Generated AIConfig Json: \n",
      "('{\\n'\n",
      " '  \"name\": \"Wow, I have such a cool name!\",\\n'\n",
      " '  \"schema_version\": \"latest\",\\n'\n",
      " '  \"metadata\": {\\n'\n",
      " '    \"parameters\": {},\\n'\n",
      " '    \"models\": {},\\n'\n",
      " '    \"gpt-3.5-turbo\": {\\n'\n",
      " '      \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '      \"top_p\": 1,\\n'\n",
      " '      \"temperature\": 1\\n'\n",
      " '    }\\n'\n",
      " '  },\\n'\n",
      " '  \"description\": \"And an even cooler description!\",\\n'\n",
      " '  \"prompts\": [\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_0\",\\n'\n",
      " '      \"input\": \"Hi\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1,\\n'\n",
      " '            \"stream\": false\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"content\": \"Hello! How can I assist you today?\",\\n'\n",
      " '            \"role\": \"assistant\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"id\": \"chatcmpl-8Q7IE1LMsEJeBOaHJVdJdn719HVgM\",\\n'\n",
      " '            \"created\": 1701235254,\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo-0613\",\\n'\n",
      " '            \"object\": \"chat.completion\",\\n'\n",
      " '            \"usage\": {\\n'\n",
      " '              \"completion_tokens\": 9,\\n'\n",
      " '              \"prompt_tokens\": 8,\\n'\n",
      " '              \"total_tokens\": 17\\n'\n",
      " '            },\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    }\\n'\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "\n",
    "# Set Once and every call will create an AIConfig\n",
    "aiconfig_settings = {\n",
    "    \"name\": \"Wow, I have such a cool name!\",\n",
    "    \"description\": \"And an even cooler description!\",\n",
    "    \"metadata\": {\"gpt-3.5-turbo\": {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"temperature\": 1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "openai.chat.completions.create = create_and_save_to_config(aiconfig_settings=aiconfig_settings)\n",
    "\n",
    "# Basic Execution\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"stream\": False,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Hi\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) # Creates a config saved to default path `aiconfig.json`\n",
    "print(\"Chat Completion Response: \")\n",
    "pprint.pprint(response)\n",
    "\n",
    "# `aiconfig.json`` is the default file path which stores our AIConfig\n",
    "# See next cell below for example of setting it ourselves\n",
    "print(\"\\nGenerated AIConfig Json: \")\n",
    "pretty_print_file('aiconfig.json') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Completion Streaming Response: \n",
      "Once upon a time, in a small coastal town, there lived a young girl named Emma. Emma had always been fascinated by the sea and was known for her adventurous spirit. She spent her days exploring the rocky shorelines, collecting seashells, and daydreaming about the mysteries that lay below the waves.\n",
      "\n",
      "One sunny afternoon, Emma stumbled upon an old leather-bound book half-buried in the sand. Intrigued, she carefully picked it up and brushed away the grains. The book was filled with nautical charts, sketches of sea creatures, and tales of lost treasures.\n",
      "\n",
      "Emma's curiosity got the better of her, and she decided to dive into the world of sea exploration. She sought advice from a wise old sailor in town, Captain James, who had sailed the deepest oceans. Captain James listened intently to Emma's passion and saw the spark in her eyes. He decided to mentor her on the art of navigation and taught her everything he knew about the sea.\n",
      "\n",
      "With Captain James' guidance, Emma charted her course to uncover the mysteries hidden beneath the waves. She gathered a crew of likeminded adventurers and set sail on a magnificent ship, aptly named \"The Mariner's Dream.\"\n",
      "\n",
      "Their journey was not without challenges. Storms raged, threatening to tear their ship apart, but Emma's determination held steady. They faced treacherous sea monsters, hidden reefs, and eerie legends whispered by old sailors. However, Emma's unwavering spirit and her crew's unwavering faith in her leadership carried them through.\n",
      "\n",
      "As they ventured deeper into uncharted waters, Emma discovered an ancient map inside the book she had found. The map revealed the exact location of a legendary lost city beneath the sea. This city was rumored to hold untold riches, magical artifacts, and the answer to a long-lost civilization.\n",
      "\n",
      "Driven by her thirst for knowledge and the allure of adventure, Emma navigated her crew towards the coordinates on the map. The deeper they dived, the more the world transformed around them. Schools of neon-colored fish swam by. Enormous corals formed mesmerizing underwater landscapes, and they encountered fascinating sea creatures never before seen.\n",
      "\n",
      "Finally, after weeks of searching, they stumbled upon the lost city. It shimmered with an otherworldly glow, sunken and forgotten by time. Emma and her crew explored the ancient ruins, uncovering long-forgotten treasures, rare artifacts, and secrets that had been lost for centuries.\n",
      "\n",
      "As they began their return journey, Emma realized that her true reward was not the riches she had found, but the knowledge she had acquired and the friendships she had forged. The journey had transformed her, and she knew she had found her true calling in life.\n",
      "\n",
      "Word of Emma's incredible quest spread, and more people were inspired to explore the mysteries of the sea. Emma, now a seasoned captain herself, became a teacher, guiding aspiring adventurers in their own quests.\n",
      "\n",
      "And so, the story of Emma's extraordinary journey, bound in the pages of that old leather-bound book, continued to inspire generations to come, reminding them that the greatest treasures in life are often found in the pursuit of one's passion and the depths of one's dreams.None\n",
      "Generated AIConfig Json: \n",
      "('{\\n'\n",
      " '  \"name\": \"AIConfig for my storytellinng prompt\",\\n'\n",
      " '  \"schema_version\": \"latest\",\\n'\n",
      " '  \"metadata\": {\\n'\n",
      " '    \"parameters\": {},\\n'\n",
      " '    \"models\": {},\\n'\n",
      " '    \"gpt-3.5-turbo\": {\\n'\n",
      " '      \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '      \"top_p\": 1,\\n'\n",
      " '      \"temperature\": 1\\n'\n",
      " '    }\\n'\n",
      " '  },\\n'\n",
      " '  \"description\": \"It tells a story as specified by the prompt\",\\n'\n",
      " '  \"prompts\": [\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_0\",\\n'\n",
      " '      \"input\": \"Tell me a riveting story\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1,\\n'\n",
      " '            \"stream\": true\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"content\": \"Once upon a time, in a small coastal town, there lived a young girl named Emma. Emma had always been fascinated by the sea '\n",
      " 'and was known for her adventurous spirit. She spent her days exploring the rocky shorelines, collecting seashells, and daydreaming about the '\n",
      " 'mysteries that lay below the waves.\\\\n\\\\nOne sunny afternoon, Emma stumbled upon an old leather-bound book half-buried in the sand. Intrigued, she '\n",
      " 'carefully picked it up and brushed away the grains. The book was filled with nautical charts, sketches of sea creatures, and tales of lost '\n",
      " \"treasures.\\\\n\\\\nEmma's curiosity got the better of her, and she decided to dive into the world of sea exploration. She sought advice from a wise \"\n",
      " \"old sailor in town, Captain James, who had sailed the deepest oceans. Captain James listened intently to Emma's passion and saw the spark in her \"\n",
      " \"eyes. He decided to mentor her on the art of navigation and taught her everything he knew about the sea.\\\\n\\\\nWith Captain James' guidance, Emma \"\n",
      " 'charted her course to uncover the mysteries hidden beneath the waves. She gathered a crew of likeminded adventurers and set sail on a magnificent '\n",
      " 'ship, aptly named \\\\\"The Mariner\\'s Dream.\\\\\"\\\\n\\\\nTheir journey was not without challenges. Storms raged, threatening to tear their ship apart, '\n",
      " \"but Emma's determination held steady. They faced treacherous sea monsters, hidden reefs, and eerie legends whispered by old sailors. However, \"\n",
      " \"Emma's unwavering spirit and her crew's unwavering faith in her leadership carried them through.\\\\n\\\\nAs they ventured deeper into uncharted \"\n",
      " 'waters, Emma discovered an ancient map inside the book she had found. The map revealed the exact location of a legendary lost city beneath the '\n",
      " 'sea. This city was rumored to hold untold riches, magical artifacts, and the answer to a long-lost civilization.\\\\n\\\\nDriven by her thirst for '\n",
      " 'knowledge and the allure of adventure, Emma navigated her crew towards the coordinates on the map. The deeper they dived, the more the world '\n",
      " 'transformed around them. Schools of neon-colored fish swam by. Enormous corals formed mesmerizing underwater landscapes, and they encountered '\n",
      " 'fascinating sea creatures never before seen.\\\\n\\\\nFinally, after weeks of searching, they stumbled upon the lost city. It shimmered with an '\n",
      " 'otherworldly glow, sunken and forgotten by time. Emma and her crew explored the ancient ruins, uncovering long-forgotten treasures, rare '\n",
      " 'artifacts, and secrets that had been lost for centuries.\\\\n\\\\nAs they began their return journey, Emma realized that her true reward was not the '\n",
      " 'riches she had found, but the knowledge she had acquired and the friendships she had forged. The journey had transformed her, and she knew she had '\n",
      " \"found her true calling in life.\\\\n\\\\nWord of Emma's incredible quest spread, and more people were inspired to explore the mysteries of the sea. \"\n",
      " \"Emma, now a seasoned captain herself, became a teacher, guiding aspiring adventurers in their own quests.\\\\n\\\\nAnd so, the story of Emma's \"\n",
      " 'extraordinary journey, bound in the pages of that old leather-bound book, continued to inspire generations to come, reminding them that the '\n",
      " 'greatest treasures in life are often found in the pursuit of one\\'s passion and the depths of one\\'s dreams.\",\\n'\n",
      " '            \"role\": \"assistant\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    }\\n'\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "\n",
    "# Set Once and every call will create an AIConfig, this time setting the file path\n",
    "storytelling_aiconfig_file_path = \"storytelling.aiconfig.json\"\n",
    "aiconfig_settings = {\n",
    "    \"name\": \"AIConfig for my storytellinng prompt\",\n",
    "    \"description\": \"It tells a story as specified by the prompt\",\n",
    "    \"metadata\": {\"gpt-3.5-turbo\": {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"temperature\": 1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "openai.chat.completions.create = create_and_save_to_config(config_file_path=storytelling_aiconfig_file_path, aiconfig_settings=aiconfig_settings)\n",
    "\n",
    "# Basic Streaming Execution\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"stream\": True,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Tell me a riveting story\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) # Creates a config saved to config_file_path = \"storytelling.aiconfig.json\"\n",
    "print(\"Chat Completion Streaming Response: \")\n",
    "for iteration in response:\n",
    "    iteration_dict = iteration.model_dump()\n",
    "    chunk = iteration_dict.get(\"choices\",[{}])[0].get('delta',{}).get('content','')\n",
    "    print(chunk, end = '')\n",
    "\n",
    "\n",
    "print(\"\\nGenerated AIConfig Json: \")\n",
    "pretty_print_file(storytelling_aiconfig_file_path)\n",
    "from openai import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated AIConfig Json: \n",
      "('{\\n'\n",
      " '  \"name\": \"AIConfig for my storytellinng prompt\",\\n'\n",
      " '  \"schema_version\": \"latest\",\\n'\n",
      " '  \"metadata\": {\\n'\n",
      " '    \"parameters\": {},\\n'\n",
      " '    \"models\": {},\\n'\n",
      " '    \"gpt-3.5-turbo\": {\\n'\n",
      " '      \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '      \"top_p\": 1,\\n'\n",
      " '      \"temperature\": 1\\n'\n",
      " '    }\\n'\n",
      " '  },\\n'\n",
      " '  \"description\": \"It tells a story as specified by the prompt\",\\n'\n",
      " '  \"prompts\": [\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_0\",\\n'\n",
      " '      \"input\": \"Tell me a riveting story\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1,\\n'\n",
      " '            \"stream\": true\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"content\": \"Once upon a time, in a small coastal town, there lived a young girl named Emma. Emma had always been fascinated by the sea '\n",
      " 'and was known for her adventurous spirit. She spent her days exploring the rocky shorelines, collecting seashells, and daydreaming about the '\n",
      " 'mysteries that lay below the waves.\\\\n\\\\nOne sunny afternoon, Emma stumbled upon an old leather-bound book half-buried in the sand. Intrigued, she '\n",
      " 'carefully picked it up and brushed away the grains. The book was filled with nautical charts, sketches of sea creatures, and tales of lost '\n",
      " \"treasures.\\\\n\\\\nEmma's curiosity got the better of her, and she decided to dive into the world of sea exploration. She sought advice from a wise \"\n",
      " \"old sailor in town, Captain James, who had sailed the deepest oceans. Captain James listened intently to Emma's passion and saw the spark in her \"\n",
      " \"eyes. He decided to mentor her on the art of navigation and taught her everything he knew about the sea.\\\\n\\\\nWith Captain James' guidance, Emma \"\n",
      " 'charted her course to uncover the mysteries hidden beneath the waves. She gathered a crew of likeminded adventurers and set sail on a magnificent '\n",
      " 'ship, aptly named \\\\\"The Mariner\\'s Dream.\\\\\"\\\\n\\\\nTheir journey was not without challenges. Storms raged, threatening to tear their ship apart, '\n",
      " \"but Emma's determination held steady. They faced treacherous sea monsters, hidden reefs, and eerie legends whispered by old sailors. However, \"\n",
      " \"Emma's unwavering spirit and her crew's unwavering faith in her leadership carried them through.\\\\n\\\\nAs they ventured deeper into uncharted \"\n",
      " 'waters, Emma discovered an ancient map inside the book she had found. The map revealed the exact location of a legendary lost city beneath the '\n",
      " 'sea. This city was rumored to hold untold riches, magical artifacts, and the answer to a long-lost civilization.\\\\n\\\\nDriven by her thirst for '\n",
      " 'knowledge and the allure of adventure, Emma navigated her crew towards the coordinates on the map. The deeper they dived, the more the world '\n",
      " 'transformed around them. Schools of neon-colored fish swam by. Enormous corals formed mesmerizing underwater landscapes, and they encountered '\n",
      " 'fascinating sea creatures never before seen.\\\\n\\\\nFinally, after weeks of searching, they stumbled upon the lost city. It shimmered with an '\n",
      " 'otherworldly glow, sunken and forgotten by time. Emma and her crew explored the ancient ruins, uncovering long-forgotten treasures, rare '\n",
      " 'artifacts, and secrets that had been lost for centuries.\\\\n\\\\nAs they began their return journey, Emma realized that her true reward was not the '\n",
      " 'riches she had found, but the knowledge she had acquired and the friendships she had forged. The journey had transformed her, and she knew she had '\n",
      " \"found her true calling in life.\\\\n\\\\nWord of Emma's incredible quest spread, and more people were inspired to explore the mysteries of the sea. \"\n",
      " \"Emma, now a seasoned captain herself, became a teacher, guiding aspiring adventurers in their own quests.\\\\n\\\\nAnd so, the story of Emma's \"\n",
      " 'extraordinary journey, bound in the pages of that old leather-bound book, continued to inspire generations to come, reminding them that the '\n",
      " 'greatest treasures in life are often found in the pursuit of one\\'s passion and the depths of one\\'s dreams.\",\\n'\n",
      " '            \"role\": \"assistant\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_1\",\\n'\n",
      " '      \"input\": \"Tell me a joke about apples\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"role\": \"assistant\",\\n'\n",
      " '            \"content\": \"Why did the apple go to school?\\\\n\\\\nBecause it wanted to be a \\\\\"smarty-pie\\\\\"!\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {}\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"prompt_2\",\\n'\n",
      " '      \"input\": \"Tell this joke in a shakespearean rhetoric\",\\n'\n",
      " '      \"metadata\": {\\n'\n",
      " '        \"model\": {\\n'\n",
      " '          \"name\": \"gpt-3.5-turbo\",\\n'\n",
      " '          \"settings\": {\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo\",\\n'\n",
      " '            \"top_p\": 1,\\n'\n",
      " '            \"max_tokens\": 3000,\\n'\n",
      " '            \"temperature\": 1\\n'\n",
      " '          }\\n'\n",
      " '        },\\n'\n",
      " '        \"parameters\": {},\\n'\n",
      " '        \"remember_chat_context\": true\\n'\n",
      " '      },\\n'\n",
      " '      \"outputs\": [\\n'\n",
      " '        {\\n'\n",
      " '          \"output_type\": \"execute_result\",\\n'\n",
      " '          \"execution_count\": 0,\\n'\n",
      " '          \"data\": {\\n'\n",
      " '            \"content\": \"Verily, prithee, hearken unto this jest of apples! Why, pray tell, did the noble apple embark upon the journey to the '\n",
      " \"halls of learning? Forsooth, 'twas in pursuit of knowledge that this fruit set forth!\\\\n\\\\nMethinks, perchance, the apple yearned to become a \"\n",
      " '\\\\\"smarty-pie\\\\\"!\",\\n'\n",
      " '            \"role\": \"assistant\"\\n'\n",
      " '          },\\n'\n",
      " '          \"metadata\": {\\n'\n",
      " '            \"id\": \"chatcmpl-8Q7IUbdMH2uFEoyBxVkzVUEvDWUGO\",\\n'\n",
      " '            \"created\": 1701235270,\\n'\n",
      " '            \"model\": \"gpt-3.5-turbo-0613\",\\n'\n",
      " '            \"object\": \"chat.completion\",\\n'\n",
      " '            \"usage\": {\\n'\n",
      " '              \"completion_tokens\": 72,\\n'\n",
      " '              \"prompt_tokens\": 50,\\n'\n",
      " '              \"total_tokens\": 122\\n'\n",
      " '            },\\n'\n",
      " '            \"finish_reason\": \"stop\"\\n'\n",
      " '          }\\n'\n",
      " '        }\\n'\n",
      " '      ]\\n'\n",
      " '    }\\n'\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from aiconfig.Config import AIConfigRuntime\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "\n",
    "# Load an existing AIConfig\n",
    "storytelling_aiconfig_file_path = \"storytelling.aiconfig.json\"\n",
    "aiconfig = AIConfigRuntime.load(storytelling_aiconfig_file_path) # load the second aiconfig we just created and use it\n",
    "openai.chat.completions.create = create_and_save_to_config(aiconfig=aiconfig)\n",
    "\n",
    "# Compounded Execution\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Tell me a joke about apples\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) # Config was previously loaded from 'my-second-aiconfig.json. New Prompt gets added to the AIConfig Object and also saved to the same file\n",
    "\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Tell me a joke about apples\",\n",
    "                    \"role\": \"user\",\n",
    "                },\n",
    "                 {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Why did the apple go to school?\\n\\nBecause it wanted to be a \\\"smarty-pie\\\"!\"\n",
    "      },                                \n",
    "      {\n",
    "                    \"content\": \"Tell this joke in a shakespearean rhetoric\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) # Config is updated with the second prompt keeping the history intact\n",
    "\n",
    "print(\"\\nGenerated AIConfig Json: \")\n",
    "pretty_print_file(storytelling_aiconfig_file_path) # open the config yourself and check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8Q7JBIW411VSvL9wINadfcRpwK0rf', choices=[Choice(finish_reason='function_call', index=0, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"location\": \"Boston, MA\"\\n}', name='get_current_weather'), tool_calls=None))], created=1701235313, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=18, prompt_tokens=82, total_tokens=100))\n",
      "ChatCompletion(id='chatcmpl-8Q7JC5m36VdAoL0FIlEpxThSbFG8y', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='The current weather in Boston is sunny with a temperature of 22 degrees Celsius.', role='assistant', function_call=None, tool_calls=None))], created=1701235314, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=17, prompt_tokens=134, total_tokens=151))\n"
     ]
    }
   ],
   "source": [
    "# Function Call Capture\n",
    "from aiconfig.Config import AIConfigRuntime\n",
    "import openai\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "\n",
    "# Set aiconfig\n",
    "function_call_filepath = \"function_call.aiconfig.json\"\n",
    "aiconfig_settings = {\n",
    "    \"name\": \"AIConfig for my weather function\",\n",
    "    \"description\": \"It tells the weather for a given location\"\n",
    "}\n",
    "openai.chat.completions.create = create_and_save_to_config(config_file_path=function_call_filepath, aiconfig_settings=aiconfig_settings)\n",
    "\n",
    "def get_current_weather(location, unit):\n",
    "    return { \"temperature\": 22, \"unit\": \"celsius\", \"description\": \"Sunny\" }\n",
    "\n",
    "completion_params = {\n",
    "    \"model\": \"gpt-3.5-turbo-0613\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is the weather like in Boston?\"}],\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) \n",
    "\n",
    "function_call_response = get_current_weather(location=\"Boston\", unit=\"celsius\")\n",
    "print(response)\n",
    "\n",
    "completion_params = {\n",
    "  \"model\": \"gpt-3.5-turbo-0613\",\n",
    "  \"messages\": [\n",
    "    {\"role\": \"user\", \"content\": \"What is the weather like in Boston?\"},\n",
    "    {\"role\": \"assistant\", \"content\": 'null', \"function_call\": {\n",
    "          \"name\": \"get_current_weather\",\n",
    "          \"arguments\": \"{\\n  \\\"location\\\": \\\"Boston, MA\\\"\\n}\"\n",
    "        }},\n",
    "    {\"role\": \"function\", \"name\": \"get_current_weather\", \"content\": str(function_call_response)}\n",
    "\n",
    "  ],\n",
    "  \"functions\": [\n",
    "    {\n",
    "      \"name\": \"get_current_weather\",\n",
    "      \"description\": \"Get the current weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "          },\n",
    "          \"unit\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "response = openai.chat.completions.create(**completion_params) \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Instantiate a client\n",
    "from aiconfig.ChatCompletion import create_and_save_to_config\n",
    "\n",
    "client = openai.Client()\n",
    "client.chat.completions.create = create_and_save_to_config()\n",
    "\n",
    "completion_params = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"top_p\": 1,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"temperature\": 1,\n",
    "            \"stream\": False,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"content\": \"Hi there!\",\n",
    "                    \"role\": \"user\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "response = client.chat.completions.create(**completion_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ExecuteResult(output_type='execute_result', execution_count=0, data={'content': 'Hello! How can I help you today?', 'role': 'assistant'}, mime_type=None, metadata={'id': 'chatcmpl-8Q7JXjM0nppiBauLFgcgnfwAjfUya', 'created': 1701235335, 'model': 'gpt-3.5-turbo-0613', 'object': 'chat.completion', 'usage': {'completion_tokens': 9, 'prompt_tokens': 23, 'total_tokens': 32}, 'finish_reason': 'stop'})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aiconfig import AIConfigRuntime\n",
    "from aiconfig import InferenceOptions\n",
    "\n",
    "config = AIConfigRuntime.load(\"aiconfig.json\")\n",
    "inference_options = InferenceOptions(stream=False)\n",
    "await config.run(\"prompt_0\", options=inference_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
